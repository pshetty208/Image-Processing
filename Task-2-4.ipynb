{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "IOtPmKDQMEjj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-5PxoyHMKUb",
    "outputId": "15b12759-4d5d-4830-d444-3d1cad4dd0d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "1PYkSAb8MP9E"
   },
   "outputs": [],
   "source": [
    "train_data_path = '/content/drive/MyDrive/Colab Notebooks/2_segmentation/2_segmentation/Train/'\n",
    "test_path = '/content/drive/MyDrive/Colab Notebooks/2_segmentation/2_segmentation/Test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_UPWBFsy47s"
   },
   "source": [
    "# **Data Load Task 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TLfmsDxbLc0",
    "outputId": "eee23b6a-3f37-4ab0-eb37-778b24dbb187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Images Shape: (400, 512, 512, 3)\n",
      "Resized Masks Shape: (400, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "def load(data_directory):\n",
    "    images_dir = os.path.join(data_directory, 'Ids')\n",
    "    masks_dir = os.path.join(data_directory, 'GroundTruth')\n",
    "    image_files = sorted(os.listdir(images_dir))\n",
    "    mask_files = sorted(os.listdir(masks_dir))\n",
    "\n",
    "\n",
    "    # Initialize lists to store resized images and masks\n",
    "    resized_images = []\n",
    "    resized_masks = []\n",
    "\n",
    "    # Loop through images and masks, resize, and append to the\n",
    "    for img_name, msk_name in zip(image_files, mask_files):\n",
    "      image = tf.keras.preprocessing.image.load_img(\n",
    "      os.path.join(images_dir,img_name),target_size = (512,512)\n",
    "      )\n",
    "      mask =tf.keras.preprocessing.image.load_img(\n",
    "      os.path.join(masks_dir,msk_name),color_mode = \"grayscale\",target_size = (512,512)\n",
    "      )\n",
    "      image= tf.keras.preprocessing.image.img_to_array(image)/255.0\n",
    "      mask= tf.keras.preprocessing.image.img_to_array(mask)/255.0\n",
    "      resized_images.append(image)\n",
    "      resized_masks.append(mask)\n",
    "\n",
    "    return np.array(resized_images),np.array(resized_masks)\n",
    "\n",
    "resized_images_np,resized_masks = load(train_data_path)\n",
    "resized_test_images_np,resized_masks_np = load(test_path)\n",
    "print(\"Resized Images Shape:\", resized_images_np.shape)\n",
    "print(\"Resized Masks Shape:\", resized_masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO602Oz9DPl7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0TORdTgDShY"
   },
   "source": [
    "**Ground Truth and Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GuPJx90fXFAD",
    "outputId": "b56ed335-ae02-4f9f-b22d-a4d2a922dc8c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resized_images_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m visualize_sample(\u001b[43mresized_images_np\u001b[49m, resized_masks)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resized_images_np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sample(images, masks, num_samples=5):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        index = np.random.randint(len(images))  # Randomly select an index\n",
    "        image = images[index]\n",
    "        mask = masks[index]\n",
    "\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title('Image')\n",
    "\n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\n",
    "visualize_sample(resized_images_np, resized_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtH4wNg1DXvZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_F2iYtlDYgZ"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdChaLXjMfU4",
    "outputId": "55850404-6588-44ba-fc8d-4b5b91b3bc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 512, 512, 32)         896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 32)         9248      ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 32)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 64)         18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 64)         0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 128, 128, 128)        131200    ['conv2d_7[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128, 128, 256)        0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 128)        295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 256, 256, 64)         32832     ['conv2d_9[0][0]']            \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 512, 512, 32)         8224      ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 512, 512, 64)         0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 512, 512, 32)         18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 512, 512, 32)         9248      ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 512, 512, 1)          33        ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1925601 (7.35 MB)\n",
      "Trainable params: 1925601 (7.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "\n",
    "def unet(input_shape=(512, 512, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Bottom\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
    "    up5 = concatenate([up5, conv3], axis=3)\n",
    "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(up5)\n",
    "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    up6 = concatenate([up6, conv2], axis=3)\n",
    "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv1], axis=3)\n",
    "    conv7 = Conv2D(32, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(32, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv7)  # Change 1 to the number of classes for multi-class segmentation\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Create an instance of the UNet model\n",
    "model = unet()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61CO5axhLkOT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model with the specified optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZD4QtE9W2w0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Metric to monitor\n",
    "                               patience=5,         # Number of epochs with no improvement after which training will be stopped\n",
    "                               restore_best_weights=True)  # Restore model weights from the epoch with the best value of the monitored metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-fWY3F5L2EE",
    "outputId": "9a29343c-2c8d-405c-afec-125d42ec3908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8357 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 147s 11s/step - loss: 0.5459 - accuracy: 0.8357\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3907 - accuracy: 0.8973 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.3907 - accuracy: 0.8973\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.8973 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 139s 11s/step - loss: 0.3142 - accuracy: 0.8973\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.8973 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 149s 11s/step - loss: 0.2416 - accuracy: 0.8973\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.8973 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.1397 - accuracy: 0.8973\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.9278 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.1142 - accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9618 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.1046 - accuracy: 0.9618\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9369 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.1532 - accuracy: 0.9369\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9597 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 140s 11s/step - loss: 0.0941 - accuracy: 0.9597\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9726 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "13/13 [==============================] - 140s 11s/step - loss: 0.0715 - accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a904b0ee380>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(resized_images_np ,resized_masks, epochs=10,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U22A7NerqhL3",
    "outputId": "939d5f69-b3b2-4d19-91ac-019366524099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 5s/step\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "pred= model.predict(resized_test_images_np)\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "2E0mltGQ5pYL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('/content/drive/MyDrive/Colab Notebooks/id_card_seg1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CGgjBbfONJu",
    "outputId": "02504116-fd47-461f-c61b-e5a0df8cbe41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 192s 42s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred= model1.predict(resized_test_images_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6rTcXE3F5p8"
   },
   "source": [
    "#Result Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PwYsqbGD5PMS",
    "outputId": "a6a2d904-d1e7-4176-ec0c-4cb2ae3af9fd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m cutout \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m \u001b[38;5;241m*\u001b[39m resized_test_images_np\n\u001b[1;32m     32\u001b[0m visualize_sample(resized_test_images_np, pred,cutout,resized_masks_np)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_sample(images, masks, cut_out, resized_masks, num_samples=5):\n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(20, 20))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        index = np.random.randint(len(images))  # Randomly select an index\n",
    "        image = images[index]\n",
    "        mask = masks[index]\n",
    "        cut_out_mask = cut_out[index]\n",
    "        resized_mask = resized_masks[index]\n",
    "\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title('Image')\n",
    "\n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Mask')\n",
    "\n",
    "        axes[i, 2].imshow(cut_out_mask)\n",
    "        axes[i, 2].set_title('Cut-out Mask')\n",
    "\n",
    "        axes[i, 3].imshow(resized_mask, cmap='gray')\n",
    "        axes[i, 3].set_title('Ground Truth')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\n",
    "cutout = pred * resized_test_images_np\n",
    "visualize_sample(resized_test_images_np, pred,cutout,resized_masks_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O1qTzt-F_Wl"
   },
   "source": [
    "# Task 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4k-S7XJaDMP"
   },
   "outputs": [],
   "source": [
    "train_data_path_f = '/content/drive/MyDrive/Colab Notebooks/4_cleaning/4_cleaning/Train/'\n",
    "test_path_f = '/content/drive/MyDrive/Colab Notebooks/4_cleaning/4_cleaning/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIvERKQpaLqV",
    "outputId": "7b037fd6-1b43-4682-a9ef-b3c03cfe1012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Images Shape: (400, 512, 512, 3)\n",
      "Resized Masks Shape: (400, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "def four_load(data_directory):\n",
    "    images_dir = os.path.join(data_directory, 'Ids')\n",
    "    masks_dir = os.path.join(data_directory, 'GroundTruth')\n",
    "    image_files = sorted(os.listdir(images_dir))\n",
    "    mask_files = sorted(os.listdir(masks_dir))\n",
    "\n",
    "\n",
    "    # Initialize lists to store resized images and masks\n",
    "    resized_images = []\n",
    "    resized_masks = []\n",
    "\n",
    "    # Loop through images and masks, resize, and append to the\n",
    "    for img_name, msk_name in zip(image_files, mask_files):\n",
    "      image = tf.keras.preprocessing.image.load_img(\n",
    "      os.path.join(images_dir,img_name),target_size = (512,512)\n",
    "      )\n",
    "      mask =tf.keras.preprocessing.image.load_img(\n",
    "      os.path.join(masks_dir,msk_name),color_mode = \"grayscale\",target_size = (512,512)\n",
    "      )\n",
    "      image= tf.keras.preprocessing.image.img_to_array(image)/255.0\n",
    "      mask= tf.keras.preprocessing.image.img_to_array(mask)/255.0\n",
    "      resized_images.append(image)\n",
    "      resized_masks.append(mask)\n",
    "\n",
    "    return np.array(resized_images),np.array(resized_masks)\n",
    "\n",
    "resized_images_np1,resized_masks1 = four_load(train_data_path_f)\n",
    "resized_test_images_np1,resized_masks_np11 = four_load(test_path_f)\n",
    "print(\"Resized Images Shape:\", resized_images_np1.shape)\n",
    "print(\"Resized Masks Shape:\", resized_masks1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE3aTG37Tnmp",
    "outputId": "dfa9c4c0-9284-492d-bb0f-5d4a26c75b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 512, 512, 32)         896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 512, 512, 32)         9248      ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 32)         0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 64)         18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 64)         0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 128)        73856     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 128)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 256)          295168    ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTr  (None, 128, 128, 128)        131200    ['conv2d_7[0][0]']            \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128, 128, 256)        0         ['conv2d_transpose[0][0]',    \n",
      "                                                                     'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 128, 128, 128)        295040    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2D  (None, 256, 256, 64)         32832     ['conv2d_9[0][0]']            \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256, 256, 128)        0         ['conv2d_transpose_1[0][0]',  \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 64)         73792     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 64)         36928     ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2D  (None, 512, 512, 32)         8224      ['conv2d_11[0][0]']           \n",
      " Transpose)                                                                                       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 512, 512, 64)         0         ['conv2d_transpose_2[0][0]',  \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 512, 512, 32)         18464     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 512, 512, 32)         9248      ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 512, 512, 1)          33        ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1925601 (7.35 MB)\n",
      "Trainable params: 1925601 (7.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arGACvY9UEp3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compile the model with the specified optimizer\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLvCqm1QUg9S",
    "outputId": "eb2dc276-725b-4114-fcbd-3b88c57e6550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='loss',  # Metric to monitor\n",
    "                               patience=2,         # Number of epochs with no improvement after which training will be stopped\n",
    "                         restore_best_weights=True)  # Restore model weights from the epoch with the best value of the monitored metric\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(resized_images_np1, resized_masks1,  # Training data\n",
    "#                     validation_data=(x_val, y_val),  # Validation data\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=4,# Maximum number of epochs\n",
    "                    batch_size=16,       # Batch size\n",
    "                    callbacks=[early_stopping])  # Early stopping callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCMhnSbjHylP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXe_aC6UHyAx"
   },
   "source": [
    "# Task 4 Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "u2W5GWPkvgMA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('/content/drive/MyDrive/Colab Notebooks/id_card_clean.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bvR3xx_p5qp",
    "outputId": "47443797-dafe-4508-ecd4-2620fc8eedc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 199s 43s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1= model1.predict(resized_test_images_np1,verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3_AoqQjSnaR",
    "outputId": "48736d11-f4b4-4d1c-862a-c500809eae2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 37ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBEFtAv0HquX"
   },
   "source": [
    "# Result Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6h4Idyk0R__N",
    "outputId": "e80ab4d4-3692-430f-bee0-91e9a0e4922f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resized_test_images_np1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m visualize_sample(\u001b[43mresized_test_images_np1\u001b[49m, pred1,resized_masks_np11)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resized_test_images_np1' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_sample(images, masks, resized_masks, num_samples=5):\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(20, 20))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        index = np.random.randint(len(images))  # Randomly select an index\n",
    "        image = images[index]\n",
    "        mask = masks[index]\n",
    "\n",
    "        resized_mask = resized_masks[index]\n",
    "\n",
    "        axes[i, 0].imshow(image)\n",
    "        axes[i, 0].set_title('Image')\n",
    "\n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Cleaned image')\n",
    "\n",
    "        axes[i, 2].imshow(resized_mask, cmap='gray')\n",
    "        axes[i, 2].set_title('Ground Truth')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming 'train_images' and 'train_masks' are loaded and preprocessed\n",
    "\n",
    "visualize_sample(resized_test_images_np1, pred1,resized_masks_np11)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
